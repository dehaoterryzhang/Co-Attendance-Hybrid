{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Import Python Libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from datetime import datetime, timedelta"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Load/transform data through sparksql\r\n",
        "query = '''\r\n",
        "select t1.EmployeeHashID, t1.date, t1.AssignedBuilding_SwipedIn, t1.assignedbuilding, t1.assignedbuilding_region, \r\n",
        "t1.assignedbuilding_country, t1.RoomTypeDesc, t1.HirePost20200301, t1.JobCategory, t2.EmployeeHashID as Mngr_ID, \r\n",
        "CASE WHEN t2.assignedbuilding = t1.assignedbuilding then 1 else 0 end as Mngr_Colo, t2.AssignedBuilding_SwipedIn as Mngr_Swiped, \r\n",
        "Num_Teammate, Num_Teammate_Colo, Num_ColoTeammate_Swiped from assignedattendance as t1\r\n",
        "LEFT JOIN\r\n",
        "(select * from assignedattendance) as t2\r\n",
        "on t1.date = t2.date and t1.ManagerHashedID = t2.EmployeeHashID\r\n",
        "LEFT JOIN\r\n",
        "(select EmployeeHashID, date, count(distinct Teammate_ID) as Num_Teammate, SUM(Teammate_Colo) as Num_Teammate_Colo, SUM(ColoTeammate_Swiped) as Num_ColoTeammate_Swiped from \r\n",
        "(select t1.EmployeeHashID, t1.date, t1.AssignedBuilding_SwipedIn, t1.assignedbuilding, t2.EmployeeHashID as Teammate_ID, \r\n",
        "CASE WHEN t1.assignedbuilding = t2.assignedbuilding then 1 else 0 end as Teammate_Colo, \r\n",
        "CASE WHEN t1.assignedbuilding = t2.assignedbuilding AND t2.AssignedBuilding_SwipedIn = 1 then 1 else 0 end as ColoTeammate_Swiped from assignedattendance as t1\r\n",
        "LEFT JOIN\r\n",
        "(select * from assignedattendance) as t2\r\n",
        "on t1.date = t2.date and t1.ManagerHashedID = t2.ManagerHashedID and t1.EmployeeHashID <> t2.EmployeeHashID)\r\n",
        "group by EmployeeHashID, date) as t3\r\n",
        "on t1.date = t3.date and t1.EmployeeHashID = t3.EmployeeHashID\r\n",
        "where t1.ManagerHashedID IS NOT NULL\r\n",
        "'''\r\n",
        "sdf = spark.sql(query)\r\n",
        "\r\n",
        "#Restrict to co-located manager and at least one co-located teammate\r\n",
        "sdf = sdf.filter(sdf.Mngr_Colo == 1)\r\n",
        "sdf = sdf.filter(sdf.Num_Teammate_Colo >= 1)\r\n",
        "\r\n",
        "sdf.createOrReplaceTempView(\"t_sdf\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## US Time Series of Conditional Probability for the Four Groups (Fig 1a)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#US Time Series Transformation for Conditional Probability\r\n",
        "query = '''\r\n",
        "select date, count(distinct EmployeeHashID) as HC, \r\n",
        "SUM(AssignedBuilding_SwipedIn) as Onsite_HC, \r\n",
        "SUM(CASE WHEN Mngr_Swiped = 1 and Num_ColoTeammate_Swiped >= 1 then 1 ELSE 0 end) as MngrOnTeamOn,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 1 and Num_ColoTeammate_Swiped >= 1 and AssignedBuilding_SwipedIn = 1 then 1 ELSE 0 end) as Onsite_MngrOnTeamOn,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 1 and Num_ColoTeammate_Swiped = 0 then 1 ELSE 0 end) as MngrOnTeamOff,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 1 and Num_ColoTeammate_Swiped = 0 and AssignedBuilding_SwipedIn = 1 then 1 ELSE 0 end) as Onsite_MngrOnTeamOff,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 0 and Num_ColoTeammate_Swiped >= 1 then 1 ELSE 0 end) as MngrOffTeamOn,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 0 and Num_ColoTeammate_Swiped >= 1 and AssignedBuilding_SwipedIn = 1 then 1 ELSE 0 end) as Onsite_MngrOffTeamOn,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 0 and Num_ColoTeammate_Swiped = 0 then 1 ELSE 0 end) as MngrOffTeamOff,\r\n",
        "SUM(CASE WHEN Mngr_Swiped = 0 and Num_ColoTeammate_Swiped = 0 and AssignedBuilding_SwipedIn = 1 then 1 ELSE 0 end) as Onsite_MngrOffTeamOff\r\n",
        "from t_sdf where assignedbuilding_region = 'US HQ' and date >= '2021-12-28' and date <= '2022-05-27' \r\n",
        "and date not in ('2021-12-31', '2022-01-17', '2022-02-21')\r\n",
        "group by date\r\n",
        "ORDER BY date\r\n",
        "'''\r\n",
        "us_df = spark.sql(query)\r\n",
        "us_df.createOrReplaceTempView(\"US\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the 'US_Time_Series_Viz' script for plotting the time series of conditional attendance probability"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TWFE Modeling for US, India, and Ireland (Fig 1b)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pandas Transformation/processing\r\n",
        "def processing(sdf, region, holidays, open_date):\r\n",
        "    date_holidays = {}\r\n",
        "    date_holidays['US'] = ['2021-12-31', '2022-01-17', '2022-02-21']\r\n",
        "    date_holidays['IN'] = ['2022-01-26', '2022-04-14', '2022-04-15']\r\n",
        "    date_holidays['IE'] = ['2022-03-17', '2022-03-18', '2022-04-18', '2022-06-06']\r\n",
        "    \r\n",
        "    df = sdf.filter(sdf.assignedbuilding_region == region).toPandas()\r\n",
        "    df = df.loc[~df.date.isin(date_holidays[holidays])]\r\n",
        "\r\n",
        "    df['date_dt'] = pd.to_datetime(df['date'])\r\n",
        "    df['day_of_week'] = df['date_dt'].dt.strftime('%A')\r\n",
        "    df = df.loc[~df.day_of_week.isin(['Saturday', 'Sunday'])]\r\n",
        "\r\n",
        "    df['Perc_ColoTeammate_Swiped'] = df['Num_ColoTeammate_Swiped'] / df['Num_Teammate_Colo']\r\n",
        "\r\n",
        "    #cohort filtering step 1: Present in 10 days before pre starts and 10 days after post ends\r\n",
        "    open_date_dt = datetime.strptime(open_date, \"%Y-%m-%d\")\r\n",
        "    pre_empid = list(df.loc[(df.date < open_date_dt - timedelta(days=60)) & (df.date >= open_date_dt - timedelta(days=70))].EmployeeHashID.unique())\r\n",
        "    post_empid = list(df.loc[(df.date >= open_date_dt + timedelta(days=90)) & (df.date < open_date_dt + timedelta(days=100))].EmployeeHashID.unique())\r\n",
        "    empid = [i for i in pre_empid if i in post_empid]\r\n",
        "\r\n",
        "    df = df.loc[df.EmployeeHashID.isin(empid)]\r\n",
        "\r\n",
        "    #cohort filter step 2: Sufficient records in pre and post\r\n",
        "    temp1 = df.loc[(df.date >= open_date_dt - timedelta(days=60)) & (df.date < open_date_dt)].groupby('EmployeeHashID').count()['date'].reset_index()\r\n",
        "    pre_empid2 = list(temp1.loc[temp1.date >= 15].EmployeeHashID.unique())\r\n",
        "    temp2 = df.loc[(df.date >= open_date_dt + timedelta(days=30)) & (df.date <= open_date_dt + timedelta(days=90))].groupby('EmployeeHashID').count()['date'].reset_index()\r\n",
        "    post_empid2 = list(temp2.loc[temp2.date >= 15].EmployeeHashID.unique())\r\n",
        "    empid2 = [i for i in pre_empid2 if i in post_empid2]\r\n",
        "\r\n",
        "    df = df.loc[df.EmployeeHashID.isin(empid2)]\r\n",
        "\r\n",
        "    pre = df.loc[(df.date >= open_date_dt - timedelta(days=60)) & (df.date < open_date_dt)]\r\n",
        "    post = df.loc[(df.date >= open_date_dt + timedelta(days=30)) & (df.date <= open_date_dt + timedelta(days=90))]\r\n",
        "\r\n",
        "    pre_sdf = spark.createDataFrame(pre)\r\n",
        "    pre_sdf.createOrReplaceTempView(\"pre\")\r\n",
        "    post_sdf = spark.createDataFrame(post)\r\n",
        "    post_sdf.createOrReplaceTempView(\"post\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "#function that returns bife coefficients \r\n",
        "bife_mod <- function(temp, New_Hire_ind = FALSE) {\r\n",
        "    library(bife)\r\n",
        "    temp$date <- as.factor(temp$date)\r\n",
        "    temp$EmployeeHashID <- as.factor(temp$EmployeeHashID)\r\n",
        "    \r\n",
        "    if (New_Hire_ind == FALSE) {\r\n",
        "        mod <- bias_corr(bife(AssignedBuilding_SwipedIn ~ Mngr_Swiped + Perc_ColoTeammate_Swiped + date | EmployeeHashID, data=temp))\r\n",
        "        coef <- get_APEs(mod)\r\n",
        "        print(paste('Manager coef: ', as.double(coef$delta[1])))\r\n",
        "        print(paste('Teammate coef: ', as.double(coef$delta[2])))\r\n",
        "    } else {\r\n",
        "        mod <- bias_corr(bife(AssignedBuilding_SwipedIn ~ Mngr_Swiped + Perc_ColoTeammate_Swiped + HirePost20200301:Mngr_Swiped + HirePost20200301:Perc_ColoTeammate_Swiped + date | EmployeeHashID, data=temp))\r\n",
        "        coef <- get_APEs(mod)\r\n",
        "        print(paste('Manager coef: ', as.double(coef$delta[1])))\r\n",
        "        print(paste('Teammate coef: ', as.double(coef$delta[2])))\r\n",
        "        print(paste('Manager:New Hire coef: ', as.double(coef$delta[length(coef$delta)-1])))\r\n",
        "        print(paste('Teammate:New Hire coef: ', as.double(coef$delta[length(coef$delta)])))\r\n",
        "    }\r\n",
        "    \r\n",
        "}\r\n",
        "\r\n",
        "#function that returns bootstrapped standard errors\r\n",
        "bootstrap_se <- function(temp, New_Hire_ind = FALSE, replicates = 500) {\r\n",
        "    require(bife)\r\n",
        "    require(digest)\r\n",
        "    require(dplyr)\r\n",
        "\r\n",
        "    ManagerSwiped_mfx <- list()\r\n",
        "    Perc_Colo_CoRep_Swiped_mfx <- list()\r\n",
        "    newhire_mngr <- list()\r\n",
        "    newhire_team <- list()\r\n",
        "            \r\n",
        "    for (i in 1:replicates) {\r\n",
        "    temp$seed <- i\r\n",
        "    temp$original <- paste0(temp$Mngr_ID, temp$seed)\r\n",
        "    temp$hashed_team <- lapply(temp$original, function(original) digest(original, algo = \"md5\", serialize = FALSE))\r\n",
        "    temp$rand <- substr(temp$hashed_team, start=3, stop=3) < \"8\"\r\n",
        "\r\n",
        "    if (New_Hire_ind == TRUE) {\r\n",
        "        est <- bias_corr(bife(AssignedBuilding_SwipedIn ~ Mngr_Swiped + Perc_ColoTeammate_Swiped + HirePost20200301:Mngr_Swiped + HirePost20200301:Perc_ColoTeammate_Swiped + date| EmployeeHashID, temp[which(temp$rand == TRUE), ]))\r\n",
        "    } else {\r\n",
        "        est <- bias_corr(bife(AssignedBuilding_SwipedIn ~ Mngr_Swiped + Perc_ColoTeammate_Swiped + date| EmployeeHashID, temp[which(temp$rand == TRUE), ]))\r\n",
        "    }\r\n",
        "    \r\n",
        "    coefs <- get_APEs(est)\r\n",
        "    ManagerSwiped_mfx[[i]] <- as.double(coefs$delta[1])\r\n",
        "    Perc_Colo_CoRep_Swiped_mfx[[i]] <- as.double(coefs$delta[2])\r\n",
        "\r\n",
        "    if (New_Hire_ind == TRUE) {\r\n",
        "        newhire_mngr[[i]] <- as.double(coefs$delta[length(coefs$delta)-1])\r\n",
        "        newhire_team[[i]] <- as.double(coefs$delta[length(coefs$delta)])\r\n",
        "    }\r\n",
        "    }\r\n",
        "\r\n",
        "    if (New_Hire_ind == FALSE) {\r\n",
        "        res = list(\"ManagerSwiped_mfx\" = ManagerSwiped_mfx, \"Perc_Colo_CoRep_Swiped_mfx\" = Perc_Colo_CoRep_Swiped_mfx)\r\n",
        "        print(paste(\"standard error for ManagerSwiped: \", sd(unlist(res$ManagerSwiped_mfx))))\r\n",
        "        print(paste(\"standard error for Perc_Colo_CoRep_Swiped: \", sd(unlist(res$Perc_Colo_CoRep_Swiped_mfx))))\r\n",
        "    } else {\r\n",
        "        res = list(\"ManagerSwiped_mfx\" = ManagerSwiped_mfx, \"Perc_Colo_CoRep_Swiped_mfx\" = Perc_Colo_CoRep_Swiped_mfx, newhire_mngr = \"newhire_mngr\", newhire_team = \"newhire_team\")\r\n",
        "        print(paste(\"standard error for ManagerSwiped: \", sd(unlist(res$ManagerSwiped_mfx))))\r\n",
        "        print(paste(\"standard error for Perc_Colo_CoRep_Swiped: \", sd(unlist(res$Perc_Colo_CoRep_Swiped_mfx))))\r\n",
        "        print(paste(\"standard error for ManagerSwiped:New Hire: \", sd(unlist(res$newhire_mngr))))\r\n",
        "        print(paste(\"standard error for Perc_Colo_CoRep_Swiped:New Hire: \", sd(unlist(res$newhire_team))))\r\n",
        "    }\r\n",
        "}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#US\r\n",
        "processing(t_sdf, 'US HQ', 'US', '2022-02-28')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "pre <- as.data.frame(sql(\"select * from pre\"))\r\n",
        "bife_mod(pre)\r\n",
        "bootstrap_se(pre)\r\n",
        "post <- as.data.frame(sql(\"select * from post\"))\r\n",
        "bife_mod(post)\r\n",
        "bootstrap_se(post)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#India\r\n",
        "processing(t_sdf, 'India', 'IN', '2022-03-08')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "pre <- as.data.frame(sql(\"select * from pre\"))\r\n",
        "bife_mod(pre)\r\n",
        "bootstrap_se(pre)\r\n",
        "post <- as.data.frame(sql(\"select * from post\"))\r\n",
        "bife_mod(post)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ireland\r\n",
        "processing(t_sdf, 'India', 'IN', '2022-04-04')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "pre <- as.data.frame(sql(\"select * from pre\"))\r\n",
        "bife_mod(pre)\r\n",
        "bootstrap_se(pre)\r\n",
        "post <- as.data.frame(sql(\"select * from post\"))\r\n",
        "bife_mod(post)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the 'Paremetric_Estimation_Relative_Effects_Viz' script for plotting parametric estimations for co-attendance patterns across US Headquarters, India, and Ireland."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Co-attendance Patterns by Role, New Hire Status, and Workspace Type (Fig 2)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "processing(t_sdf, 'US HQ', 'US', '2022-02-28')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "# By Job Role\r\n",
        "ER <- as.data.frame(sql(\"select * from post where JobCategory = 'Engineering & Research'\"))\r\n",
        "PM <- as.data.frame(sql(\"select * from post where JobCategory = 'Product & Program Management'\"))\r\n",
        "CO <- as.data.frame(sql(\"select * from post where JobCategory = 'Corp & Ops'\"))\r\n",
        "\r\n",
        "bife_mod(ER)\r\n",
        "bootstrap_se(ER)\r\n",
        "bife_mod(PM)\r\n",
        "bootstrap_se(PM)\r\n",
        "bife_mod(CO)\r\n",
        "bootstrap_se(CO)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "# By New Hire\r\n",
        "ER <- as.data.frame(sql(\"select * from post where JobCategory = 'Engineering & Research'\"))\r\n",
        "\r\n",
        "bife_mod(ER, New_Hire_ind = TRUE)\r\n",
        "bootstrap_se(ER, New_Hire_ind = TRUE)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sparkr\r\n",
        "# By Workspace Type\r\n",
        "closed <- as.data.frame(sql(\"select * from post where JobCategory = 'Engineering & Research' and RoomTypeDesc = 'Office'\"))\r\n",
        "open <- as.data.frame(sql(\"select * from post where JobCategory = 'Engineering & Research' and RoomTypeDesc = 'Neighborhood'\"))\r\n",
        "\r\n",
        "bife_mod(closed)\r\n",
        "bootstrap_se(closed)\r\n",
        "bife_mod(open)\r\n",
        "bootstrap_se(open)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "r"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See the 'Paremetric_Estimation_Relative_Effects_Viz' script for plotting TWFE relative effects comparsion by job role, new-hire status, and workspace type."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}